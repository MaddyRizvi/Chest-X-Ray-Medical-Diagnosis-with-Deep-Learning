{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {},
  "cells": [
    {
      "id": "4cb08b9d",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.applications.densenet import DenseNet121\nfrom keras.layers import Dense, GlobalAveragePooling2D\nfrom keras.models import Model\nfrom keras import backend as K\n\nfrom keras.models import load_model\n\nimport util\nfrom public_tests import *\nfrom test_utils import *\n\nimport tensorflow as tf\ntf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)",
      "outputs": []
    },
    {
      "id": "3a8a6b42",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "train_df = pd.read_csv(\"data/nih/train-small.csv\")\nvalid_df = pd.read_csv(\"data/nih/valid-small.csv\")\n\ntest_df = pd.read_csv(\"data/nih/test.csv\")\n\ntrain_df.head()",
      "outputs": []
    },
    {
      "id": "2c0aa89b",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "labels = ['Cardiomegaly', \n          'Emphysema', \n          'Effusion', \n          'Hernia', \n          'Infiltration', \n          'Mass', \n          'Nodule', \n          'Atelectasis',\n          'Pneumothorax',\n          'Pleural_Thickening', \n          'Pneumonia', \n          'Fibrosis', \n          'Edema', \n          'Consolidation']",
      "outputs": []
    },
    {
      "id": "76fa8b7f",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "# UNQ_C1 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)\ndef check_for_leakage(df1, df2, patient_col):\n    \"\"\"\n    Return True if there any patients are in both df1 and df2.\n\n    Args:\n        df1 (dataframe): dataframe describing first dataset\n        df2 (dataframe): dataframe describing second dataset\n        patient_col (str): string name of column with patient IDs\n    \n    Returns:\n        leakage (bool): True if there is leakage, otherwise False\n    \"\"\"\n\n    \n    # Get unique patient IDs from both datasets\n    \n    df1_patients_unique = set(df1[patient_col].unique())\n    df2_patients_unique = set(df2[patient_col].unique())\n    \n    # Find intersection\n    patients_in_both_groups = df1_patients_unique.intersection(df2_patients_unique)\n\n    # leakage contains true if there is patient overlap, otherwise false.\n    leakage = len(patients_in_both_groups) > 0 # boolean (true if there is at least 1 patient in both groups)\n    \n    \n    return leakage",
      "outputs": []
    },
    {
      "id": "d7fd4b9c",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "### do not edit this code cell    \ncheck_for_leakage_test(check_for_leakage)",
      "outputs": []
    },
    {
      "id": "40baa6f0",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "print(\"leakage between train and valid: {}\".format(check_for_leakage(train_df, valid_df, 'PatientId')))\nprint(\"leakage between train and test: {}\".format(check_for_leakage(train_df, test_df, 'PatientId')))\nprint(\"leakage between valid and test: {}\".format(check_for_leakage(valid_df, test_df, 'PatientId')))",
      "outputs": []
    },
    {
      "id": "02afb113",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "def get_train_generator(df, image_dir, x_col, y_cols, shuffle=True, batch_size=8, seed=1, target_w = 320, target_h = 320):\n    \"\"\"\n    Return generator for training set, normalizing using batch\n    statistics.\n\n    Args:\n      train_df (dataframe): dataframe specifying training data.\n      image_dir (str): directory where image files are held.\n      x_col (str): name of column in df that holds filenames.\n      y_cols (list): list of strings that hold y labels for images.\n      batch_size (int): images per batch to be fed into model during training.\n      seed (int): random seed.\n      target_w (int): final width of input images.\n      target_h (int): final height of input images.\n    \n    Returns:\n        train_generator (DataFrameIterator): iterator over training set\n    \"\"\"        \n    print(\"getting train generator...\") \n    # normalize images\n    image_generator = ImageDataGenerator(\n        samplewise_center=True,\n        samplewise_std_normalization= True)\n    \n    # flow from directory with specified batch size\n    # and target image size\n    generator = image_generator.flow_from_dataframe(\n            dataframe=df,\n            directory=image_dir,\n            x_col=x_col,\n            y_col=y_cols,\n            class_mode=\"raw\",\n            batch_size=batch_size,\n            shuffle=shuffle,\n            seed=seed,\n            target_size=(target_w,target_h))\n    \n    return generator",
      "outputs": []
    },
    {
      "id": "31920698",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "def get_test_and_valid_generator(valid_df, test_df, train_df, image_dir, x_col, y_cols, sample_size=100, batch_size=8, seed=1, target_w = 320, target_h = 320):\n    \"\"\"\n    Return generator for validation set and test set using \n    normalization statistics from training set.\n\n    Args:\n      valid_df (dataframe): dataframe specifying validation data.\n      test_df (dataframe): dataframe specifying test data.\n      train_df (dataframe): dataframe specifying training data.\n      image_dir (str): directory where image files are held.\n      x_col (str): name of column in df that holds filenames.\n      y_cols (list): list of strings that hold y labels for images.\n      sample_size (int): size of sample to use for normalization statistics.\n      batch_size (int): images per batch to be fed into model during training.\n      seed (int): random seed.\n      target_w (int): final width of input images.\n      target_h (int): final height of input images.\n    \n    Returns:\n        test_generator (DataFrameIterator) and valid_generator: iterators over test set and validation set respectively\n    \"\"\"\n    print(\"getting train and valid generators...\")\n    # get generator to sample dataset\n    raw_train_generator = ImageDataGenerator().flow_from_dataframe(\n        dataframe=train_df, \n        directory=IMAGE_DIR, \n        x_col=\"Image\", \n        y_col=labels, \n        class_mode=\"raw\", \n        batch_size=sample_size, \n        shuffle=True, \n        target_size=(target_w, target_h))\n    \n    # get data sample\n    batch = raw_train_generator.next()\n    data_sample = batch[0]\n\n    # use sample to fit mean and std for test set generator\n    image_generator = ImageDataGenerator(\n        featurewise_center=True,\n        featurewise_std_normalization= True)\n    \n    # fit generator to sample from training data\n    image_generator.fit(data_sample)\n\n    # get test generator\n    valid_generator = image_generator.flow_from_dataframe(\n            dataframe=valid_df,\n            directory=image_dir,\n            x_col=x_col,\n            y_col=y_cols,\n            class_mode=\"raw\",\n            batch_size=batch_size,\n            shuffle=False,\n            seed=seed,\n            target_size=(target_w,target_h))\n\n    test_generator = image_generator.flow_from_dataframe(\n            dataframe=test_df,\n            directory=image_dir,\n            x_col=x_col,\n            y_col=y_cols,\n            class_mode=\"raw\",\n            batch_size=batch_size,\n            shuffle=False,\n            seed=seed,\n            target_size=(target_w,target_h))\n    return valid_generator, test_generator",
      "outputs": []
    },
    {
      "id": "35e72c8d",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "IMAGE_DIR = \"data/nih/images-small/\"\ntrain_generator = get_train_generator(train_df, IMAGE_DIR, \"Image\", labels)\nvalid_generator, test_generator= get_test_and_valid_generator(valid_df, test_df, train_df, IMAGE_DIR, \"Image\", labels)",
      "outputs": []
    },
    {
      "id": "6c6c9028",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "x, y = train_generator.__getitem__(4)\nplt.imshow(x[0]);",
      "outputs": []
    },
    {
      "id": "7eb2774f",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "plt.xticks(rotation=90)\nplt.bar(x=labels, height=np.mean(train_generator.labels, axis=0))\nplt.title(\"Frequency of Each Class\")\nplt.show()",
      "outputs": []
    },
    {
      "id": "3aeda038",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "# UNQ_C2 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)\ndef compute_class_freqs(labels):\n    \"\"\"\n    Compute positive and negative frequences for each class.\n\n    Args:\n        labels (np.array): matrix of labels, size (num_examples, num_classes)\n    Returns:\n        positive_frequencies (np.array): array of positive frequences for each\n                                         class, size (num_classes)\n        negative_frequencies (np.array): array of negative frequences for each\n                                         class, size (num_classes)\n    \"\"\"\n    ### START CODE HERE (REPLACE INSTANCES OF 'None' with your code) ###\n    \n    # total number of patients (rows)\n    N = labels.shape[0]\n    \n    positive_frequencies = np.sum(labels, axis=0) / N\n    negative_frequencies = 1 - positive_frequencies\n\n    ### END CODE HERE ###\n    return positive_frequencies, negative_frequencies",
      "outputs": []
    },
    {
      "id": "0c7f3481",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "### do not edit this code cell       \ncompute_class_freqs_test(compute_class_freqs)",
      "outputs": []
    },
    {
      "id": "78ceff25",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "freq_pos, freq_neg = compute_class_freqs(train_generator.labels)\nfreq_pos",
      "outputs": []
    },
    {
      "id": "63bb9cfd",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "data = pd.DataFrame({\"Class\": labels, \"Label\": \"Positive\", \"Value\": freq_pos})\ndata = data.append([{\"Class\": labels[l], \"Label\": \"Negative\", \"Value\": v} for l,v in enumerate(freq_neg)], ignore_index=True)\nplt.xticks(rotation=90)\nf = sns.barplot(x=\"Class\", y=\"Value\", hue=\"Label\" ,data=data)",
      "outputs": []
    },
    {
      "id": "571b4d71",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "pos_weights = freq_neg\nneg_weights = freq_pos\npos_contribution = freq_pos * pos_weights \nneg_contribution = freq_neg * neg_weights",
      "outputs": []
    },
    {
      "id": "bed03276",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "data = pd.DataFrame({\"Class\": labels, \"Label\": \"Positive\", \"Value\": pos_contribution})\ndata = data.append([{\"Class\": labels[l], \"Label\": \"Negative\", \"Value\": v} \n                        for l,v in enumerate(neg_contribution)], ignore_index=True)\nplt.xticks(rotation=90)\nsns.barplot(x=\"Class\", y=\"Value\", hue=\"Label\" ,data=data);",
      "outputs": []
    },
    {
      "id": "a9fcf9ec",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "# UNQ_C3 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)\ndef get_weighted_loss(pos_weights, neg_weights, epsilon=1e-7):\n    \"\"\"\n    Return weighted loss function given negative weights and positive weights.\n\n    Args:\n      pos_weights (np.array): array of positive weights for each class, size (num_classes)\n      neg_weights (np.array): array of negative weights for each class, size (num_classes)\n    \n    Returns:\n      weighted_loss (function): weighted loss function\n    \"\"\"\n    def weighted_loss(y_true, y_pred):\n        \"\"\"\n        Return weighted loss value. \n\n        Args:\n            y_true (Tensor): Tensor of true labels, size is (num_examples, num_classes)\n            y_pred (Tensor): Tensor of predicted labels, size is (num_examples, num_classes)\n        Returns:\n            loss (float): overall scalar loss summed across all classes\n        \"\"\"\n        # initialize loss to zero\n        loss = 0.0\n        \n        ### START CODE HERE (REPLACE INSTANCES OF 'None' with your code) ###\n\n        for i in range(len(pos_weights)):\n            # for each class, add average weighted loss for that class \n             loss += - K.mean(\n                pos_weights[i] * y_true[:, i] * K.log(y_pred[:, i] + epsilon) +\n                neg_weights[i] * (1 - y_true[:, i]) * K.log(1 - y_pred[:, i] + epsilon)\n            )\n        return loss\n    \n        ### END CODE HERE ###\n    return weighted_loss",
      "outputs": []
    },
    {
      "id": "69ed6e36",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "# test with a large epsilon in order to catch errors. \n# In order to pass the tests, set epsilon = 1\nepsilon = 1\n\n### do not edit anything below\nsess = K.get_session()\nget_weighted_loss_test(get_weighted_loss, epsilon, sess)",
      "outputs": []
    },
    {
      "id": "e06803b4",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "# create the base pre-trained model\nbase_model = DenseNet121(weights='models/nih/densenet.hdf5', include_top=False)\n\nx = base_model.output\n\n# add a global spatial average pooling layer\nx = GlobalAveragePooling2D()(x)\n\n# and a logistic layer\npredictions = Dense(len(labels), activation=\"sigmoid\")(x)\n\nmodel = Model(inputs=base_model.input, outputs=predictions)\nmodel.compile(optimizer='adam', loss=get_weighted_loss(pos_weights, neg_weights))",
      "outputs": []
    },
    {
      "id": "012a2458",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "history = model.fit_generator(train_generator, \n                              validation_data=valid_generator,\n                              steps_per_epoch=100, \n                              validation_steps=25, \n                              epochs = 3)\n\nplt.plot(history.history['loss'])\nplt.ylabel(\"loss\")\nplt.xlabel(\"epoch\")\nplt.title(\"Training Loss Curve\")\nplt.show()",
      "outputs": []
    },
    {
      "id": "09c001a3",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "model.load_weights(\"models/nih/pretrained_model.h5\")",
      "outputs": []
    },
    {
      "id": "3e856b78",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "predicted_vals = model.predict_generator(test_generator, steps = len(test_generator))",
      "outputs": []
    },
    {
      "id": "342c5754",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "auc_rocs = util.get_roc_curve(labels, predicted_vals, test_generator)",
      "outputs": []
    },
    {
      "id": "104e7d80",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "df = pd.read_csv(\"data/nih/train-small.csv\")\nIMAGE_DIR = \"data/nih/images-small/\"\n\n# only show the labels with top 4 AUC\nlabels_to_show = np.take(labels, np.argsort(auc_rocs)[::-1])[:4]",
      "outputs": []
    },
    {
      "id": "e17ee434",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "util.compute_gradcam(model, '00008270_015.png', IMAGE_DIR, df, labels, labels_to_show)",
      "outputs": []
    },
    {
      "id": "40b00341",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "util.compute_gradcam(model, '00011355_002.png', IMAGE_DIR, df, labels, labels_to_show)",
      "outputs": []
    },
    {
      "id": "4a3b81a3",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "util.compute_gradcam(model, '00029855_001.png', IMAGE_DIR, df, labels, labels_to_show)",
      "outputs": []
    },
    {
      "id": "16dee6f3",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "util.compute_gradcam(model, '00005410_000.png', IMAGE_DIR, df, labels, labels_to_show)",
      "outputs": []
    }
  ]
}